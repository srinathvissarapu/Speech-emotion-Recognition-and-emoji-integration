{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVEzIMYrFpEf",
        "outputId": "a6ae8d60-f838-435e-e725-4ede36e040d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA4vLC6ID715"
      },
      "source": [
        "%%capture\n",
        "!pip install pydub\n",
        "!pip install noisereduce\n",
        "!pip install pyaudio\n",
        "!pip install json-tricks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4cVP0NmD71-"
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "from json_tricks import load\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import librosa\n",
        "from pydub import AudioSegment, effects\n",
        "import noisereduce as nr\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6qXd1-vD72A",
        "outputId": "fb01ca61-5f15-4e1a-ee1e-b74afc23b2c0"
      },
      "source": [
        "saved_model_path = '/content/drive/My Drive/Colab Notebooks/model8723.json'\n",
        "saved_weights_path = '/content/drive/My Drive/Colab Notebooks/model8723_weights.h5'\n",
        "\n",
        "#Reading the model from JSON file\n",
        "with open(saved_model_path, 'r') as json_file:\n",
        "    json_savedModel = json_file.read()\n",
        "\n",
        "# Loading the model architecture, weights\n",
        "model = tf.keras.models.model_from_json(json_savedModel)\n",
        "model.load_weights(saved_weights_path)\n",
        "\n",
        "# Compiling the model with similar parameters as the original model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='RMSProp',\n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 64)           20480     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54024 (211.03 KB)\n",
            "Trainable params: 54024 (211.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyCwGZaeD72C"
      },
      "source": [
        "def preprocess(file_path, frame_length = 2048, hop_length = 512):\n",
        "\n",
        "    # Fetch sample rate.\n",
        "    _, sr = librosa.load(path = file_path, sr = None)\n",
        "    # Load audio file\n",
        "    rawsound = AudioSegment.from_file(file_path, duration = None)\n",
        "    # Normalize to 5 dBFS\n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0)\n",
        "    # Transform the audio file to np.array of samples\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Noise reduction\n",
        "    final_x = nr.reduce_noise(normal_x, sr=sr, use_tensorflow=True)\n",
        "\n",
        "\n",
        "    f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length, center=True, pad_mode='reflect').T # Energy - Root Mean Square\n",
        "    f2 = librosa.feature.zero_crossing_rate(final_x, frame_length=frame_length, hop_length=hop_length,center=True).T # ZCR\n",
        "    f3 = librosa.feature.mfcc(final_x, sr=sr, S=None, n_mfcc=13, hop_length = hop_length).T # MFCC\n",
        "    X = np.concatenate((f1, f2, f3), axis = 1)\n",
        "\n",
        "    X_3D = np.expand_dims(X, axis=0)\n",
        "\n",
        "    return X_3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXfNZp8qD72D"
      },
      "source": [
        "# Emotions list is created for a readable form of the model prediction.\n",
        "\n",
        "emotions = {\n",
        "    0 : 'neutral',\n",
        "    1 : 'calm',\n",
        "    2 : 'happy',\n",
        "    3 : 'sad',\n",
        "    4 : 'angry',\n",
        "    5 : 'fearful',\n",
        "    6 : 'disgust',\n",
        "    7 : 'suprised'\n",
        "}\n",
        "emo_list = list(emotions.values())\n",
        "\n",
        "def is_silent(data):\n",
        "    # Returns 'True' if below the 'silent' threshold\n",
        "    return max(data) < 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(audio_data, sample_rate):\n",
        "    preprocessed_audio = preprocess_audio(audio_data, sample_rate)\n",
        "    predictions = model.predict(preprocessed_audio)\n",
        "    max_emotion = np.argmax(predictions)\n",
        "    emotion_label = emotions.get(max_emotion, -1)\n",
        "    return emotion_label\n",
        "\n",
        "# Function to record audio from the microphone\n",
        "def record_microphone_audio():\n",
        "    print(\"Recording audio from the microphone. Press Enter to stop...\")\n",
        "    audio_data = sd.rec(int(10 * sample_rate), samplerate=sample_rate, channels=1)\n",
        "    sd.wait()\n",
        "    return audio_data, sample_rate\n",
        "\n",
        "sample_rate = 44100  # Set your desired sample rate\n",
        "audio_data, sample_rate = record_microphone_audio()\n",
        "\n",
        "emotion = predict_emotion(audio_data, sample_rate)\n",
        "print(\"Predicted emotion:\", emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "lhN4mckIkp8x",
        "outputId": "61d4e9c0-f39f-4f00-e9c8-bdc8571f8641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording audio from the microphone. Press Enter to stop...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-f7ebef762d20>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m44100\u001b[0m  \u001b[0;31m# Set your desired sample rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_microphone_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-f7ebef762d20>\u001b[0m in \u001b[0;36mrecord_microphone_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_microphone_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recording audio from the microphone. Press Enter to stop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0maudio_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3WpyefMSOxm",
        "outputId": "92f942d1-dc92-491f-903b-c4e08c02c67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipwin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozAXi9IPz2w0",
        "outputId": "b112b49c-2c9e-4e2a-d7fe-b31817ae0578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pipwin\n",
            "  Downloading pipwin-0.5.2.tar.gz (7.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from pipwin)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pipwin) (2.31.0)\n",
            "Collecting pyprind (from pipwin)\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pipwin) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from pipwin) (4.11.2)\n",
            "Collecting js2py (from pipwin)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pipwin) (23.2)\n",
            "Collecting pySmartDL>=1.3.1 (from pipwin)\n",
            "  Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (2.5)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py->pipwin) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py->pipwin)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (2023.7.22)\n",
            "Building wheels for collected packages: pipwin, docopt, pyjsparser\n",
            "  Building wheel for pipwin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pipwin: filename=pipwin-0.5.2-py2.py3-none-any.whl size=8769 sha256=4a122076dd4d42418c7be6f54f139ebc5ce1ed5ac672dbaa808a8da0fe00fb54\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/2c/53/c5a91c548b9f030b592608c24efda23ff966b1cceac6414765\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=5f2557ad3babdaf5226de4baf22b88dc6f484a36a6d10a438ac5ce39b7c69833\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25985 sha256=f430c876ee4bcaa3b555db7b7ee6a70d663057e48136137252732874a65e0437\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "Successfully built pipwin docopt pyjsparser\n",
            "Installing collected packages: pySmartDL, pyprind, pyjsparser, docopt, js2py, pipwin\n",
            "Successfully installed docopt-0.6.2 js2py-0.74 pipwin-0.5.2 pySmartDL-1.3.4 pyjsparser-2.7.1 pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipwin install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySw_Mt-80P_K",
        "outputId": "ee25af2a-93dc-4ea0-a5bb-340a72dab7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pipwin/command.py:66: UserWarning: Found a non Windows system. Package installation might not work.\n",
            "  warn(\"Found a non Windows system. Package installation might not work.\")\n",
            "Building cache. Hang on . . .\n",
            "Done\n",
            "Package `pyaudio` found in cache\n",
            "Downloading package . . .\n",
            "https://download.lfd.uci.edu/pythonlibs/archived/PyAudio-0.2.11-cp310-cp310-win_amd64.whl\n",
            "PyAudio-0.2.11-cp310-cp310-win_amd64.whl\n",
            "[*] 0 bytes / 111 kB @ 0 bytes/s [------------------] [0.0%, 0s left]   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b [*] 0 bytes / 111 kB @ 0 bytes/s [------------------] [0.0%, 0s left]   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b [*] 0 bytes / 111 kB @ 0 bytes/s [------------------] [0.0%, 0s left]   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b [*] 8 kB / 111 kB @ 20 kB/s [#-----------------] [7.2%, 0s left]   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b [*] 72 kB / 111 kB @ 144 kB/s [###########-------] [64.8%, 0s left]   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b [*] 111 kB / 111 kB @ 144 kB/s [##################] [100%, 0s left]    \n",
            "\u001b[31mERROR: PyAudio-0.2.11-cp310-cp310-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/pipwin\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pipwin/command.py\", line 103, in main\n",
            "    cache.install(package)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pipwin/pipwin.py\", line 301, in install\n",
            "    subprocess.check_call([executable, \"-m\", \"pip\", \"install\", wheel_file])\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 369, in check_call\n",
            "    raise CalledProcessError(retcode, cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'install', '/root/pipwin/PyAudio-0.2.11-cp310-cp310-win_amd64.whl']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzqN65p5zqPZ",
        "outputId": "d320a3e3-c483-4ad3-ee22-6f6e0d01205e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyproject.toml-based projects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMwHZBLZS6-0",
        "outputId": "fa6bee1c-80d1-4068-d321-0aecbc67b313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyproject.toml-based (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyproject.toml-based\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyAudio-0.2.14-cp310-cp310-win_amd64.whl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWz88649TufO",
        "outputId": "8bd24f95-4d82-40f1-cd9f-4e727bcb7789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Requirement 'PyAudio-0.2.14-cp310-cp310-win_amd64.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: PyAudio-0.2.14-cp310-cp310-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4DyZckD72E",
        "outputId": "e1bbcaee-69cd-46d7-ca5f-71035a0fd9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "from array import array\n",
        "import struct\n",
        "import time\n",
        "\n",
        "# Initialize variables\n",
        "RATE = 24414\n",
        "CHUNK = 512\n",
        "RECORD_SECONDS = 7.1\n",
        "\n",
        "FORMAT = pyaudio.paInt32\n",
        "CHANNELS = 1\n",
        "WAVE_OUTPUT_FILE = \"/content/drive/My Drive/Colab Notebooks/output.wav\"\n",
        "\n",
        "# Open an input channel\n",
        "p = pyaudio.PyAudio()\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "\n",
        "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
        "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
        "\n",
        "# SESSION START\n",
        "print(\"** session started\")\n",
        "total_predictions = [] # A list for all predictions in the session.\n",
        "tic = time.perf_counter()\n",
        "\n",
        "while is_silent(data) == False:\n",
        "    print(\"* recording...\")\n",
        "    frames = []\n",
        "    data = np.nan # Reset 'data' variable.\n",
        "\n",
        "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
        "\n",
        "    # Insert frames to 'output.wav'.\n",
        "    for i in range(0, timesteps):\n",
        "        data = array('l', stream.read(CHUNK))\n",
        "        frames.append(data)\n",
        "\n",
        "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
        "        wf.setnchannels(CHANNELS)\n",
        "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "        wf.setframerate(RATE)\n",
        "        wf.writeframes(b''.join(frames))\n",
        "\n",
        "    print(\"* done recording\")\n",
        "\n",
        "    x = preprocess(WAVE_OUTPUT_FILE) # 'output.wav' file preprocessing.\n",
        "    # Model's prediction => an 8 emotion probabilities array.\n",
        "    predictions = model.predict(x, use_multiprocessing=True)\n",
        "    pred_list = list(predictions)\n",
        "    pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0) # Get rid of 'array' & 'dtype' statments.\n",
        "    total_predictions.append(pred_np)\n",
        "\n",
        "    # Present emotion distribution for a sequence (7.1 secs).\n",
        "    fig = plt.figure(figsize = (10, 2))\n",
        "    plt.bar(emo_list, pred_np, color = 'darkturquoise')\n",
        "    plt.ylabel(\"Probabilty (%)\")\n",
        "    plt.show()\n",
        "\n",
        "    max_emo = np.argmax(predictions)\n",
        "    print('max emotion:', emotions.get(max_emo,-1))\n",
        "\n",
        "    print(100*'-')\n",
        "\n",
        "    # Define the last 2 seconds sequence.\n",
        "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
        "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
        "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
        "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
        "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
        "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
        "                                                                            axis =0)) , dtype = 'b')\n",
        "    if is_silent(last_frames): # If the last 2 seconds are silent, end the session.\n",
        "        break\n",
        "\n",
        "# SESSION END\n",
        "toc = time.perf_counter()\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "wf.close()\n",
        "print('** session ended')\n",
        "\n",
        "# Present emotion distribution for the whole session.\n",
        "total_predictions_np =  np.mean(np.array(total_predictions).tolist(), axis=0)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "plt.bar(emo_list, total_predictions_np, color = 'indigo')\n",
        "plt.ylabel(\"Mean probabilty (%)\")\n",
        "plt.title(\"Session Summary\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Emotions analyzed for: {(toc - tic):0.4f} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6b25612803c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sounddevice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuutT9RmUF2O",
        "outputId": "393d1e3a-226c-4b85-f565-fa3308593bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import wave\n",
        "from array import array\n",
        "import struct\n",
        "import time\n",
        "\n",
        "# Initialize variables\n",
        "RATE = 204288\n",
        "CHUNK = 512\n",
        "RECORD_SECONDS = 7.1\n",
        "\n",
        "FORMAT = np.int32\n",
        "CHANNELS = 1\n",
        "WAVE_OUTPUT_FILE = \"output.wav\"\n",
        "\n",
        "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
        "data = np.random.randint(low=0, high=500, size=512, dtype=np.int32)\n",
        "\n",
        "# SESSION START\n",
        "print(\"** session started\")\n",
        "total_predictions = []  # A list for all predictions in the session.\n",
        "tic = time.perf_counter()\n",
        "\n",
        "# Create a callback function to record audio\n",
        "def audio_callback(indata, frames, time, status):\n",
        "    if status:\n",
        "        print(\"* Error:\", status)\n",
        "    frames = array('l', indata)\n",
        "    wf.writeframes(b''.join(frames))\n",
        "\n",
        "# Open a wave file for writing\n",
        "wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(4)  # 4 bytes for int32\n",
        "wf.setframerate(RATE)\n",
        "\n",
        "# Start recording\n",
        "with sd.InputStream(callback=audio_callback, channels=1, samplerate=RATE):\n",
        "    while True:\n",
        "        print(\"* recording...\")\n",
        "        wf.writeframes(b''.join(frames))\n",
        "        frames = []\n",
        "        wf.writeframes(b''.join(frames))\n",
        "\n",
        "        if len(frames) >= RATE * RECORD_SECONDS:\n",
        "            break\n",
        "\n",
        "wf.close()\n",
        "print(\"* done recording\")\n",
        "\n",
        "x = preprocess(WAVE_OUTPUT_FILE)  # 'output.wav' file preprocessing.\n",
        "# Model's prediction => an 8 emotion probabilities array.\n",
        "predictions = model.predict(x, use_multiprocessing=True)\n",
        "pred_list = list(predictions)\n",
        "pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0)  # Get rid of 'array' & 'dtype' statements.\n",
        "total_predictions.append(pred_np)\n",
        "\n",
        "# Present emotion distribution for a sequence (7.1 secs).\n",
        "fig = plt.figure(figsize=(10, 2))\n",
        "plt.bar(emo_list, pred_np, color='darkturquoise')\n",
        "plt.ylabel(\"Probability (%)\")\n",
        "plt.show()\n",
        "\n",
        "max_emo = np.argmax(predictions)\n",
        "print('max emotion:', emotions.get(max_emo, -1))\n",
        "\n",
        "print(100 * '-')\n",
        "\n",
        "# Define the last 2 seconds sequence.\n",
        "last_frames = np.array(\n",
        "    struct.unpack(str(96 * CHUNK) + 'B',\n",
        "                  np.stack((frames[-1], frames[-2], frames[-3], frames[-4],\n",
        "                             frames[-5], frames[-6], frames[-7], frames[-8],\n",
        "                             frames[-9], frames[-10], frames[-11], frames[-12],\n",
        "                             frames[-13], frames[-14], frames[-15], frames[-16],\n",
        "                             frames[-17], frames[-18], frames[-19], frames[-20],\n",
        "                             frames[-21], frames[-22], frames[-23], frames[-24]),\n",
        "                            axis=0)),\n",
        "    dtype='b')\n",
        "if is_silent(last_frames):  # If the last 2 seconds are silent, end the session.\n",
        "    break\n",
        "\n",
        "# SESSION END\n",
        "toc = time.perf_counter()\n",
        "print('** session ended')\n",
        "\n",
        "# Present emotion distribution for the whole session.\n",
        "total_predictions_np = np.mean(np.array(total_predictions).tolist(), axis=0)\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "plt.bar(emo_list, total_predictions_np, color='indigo')\n",
        "plt.ylabel(\"Mean probability (%)\")\n",
        "plt.title(\"Session Summary\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Emotions analyzed for: {(toc - tic):0.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8uJnUGGAT-Lx",
        "outputId": "85f1c3d1-8c80-41fb-9661-89ced93394a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c3c5fbb1fc68>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msounddevice\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PortAudio library not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0m_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: PortAudio library not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gp3ReyNdOME",
        "outputId": "3144e532-c7da-48e8-b5da-a446ab620f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEN4gdYSgXCa",
        "outputId": "57b0b53f-8163-4d97-8264-1eb7a02b7095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: pyttsx3\n",
            "Successfully installed pyttsx3-2.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "import audioop\n",
        "import time\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Initialize variables\n",
        "RATE = 204288\n",
        "CHANNELS = 1\n",
        "WIDTH = 2\n",
        "RECORD_SECONDS = 7.1\n",
        "OUTPUT_FILENAME = \"output.wav\"\n",
        "\n",
        "# Create a wave file to write the audio data\n",
        "wf = wave.open(OUTPUT_FILENAME, 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(WIDTH)\n",
        "wf.setframerate(RATE)\n",
        "\n",
        "# Initialize a non-silent signals flag to start \"True\" in the first iteration.\n",
        "non_silent = True\n",
        "total_audio_data = b''  # To store the complete audio data\n",
        "tic = time.perf_counter()\n",
        "\n",
        "# Emoji for voice output\n",
        "emoji_recording = \"🎤\"\n",
        "emoji_done = \"🎵\"\n",
        "\n",
        "print(f\"{emoji_recording} Recording...\")\n",
        "\n",
        "while non_silent:\n",
        "    audio_data = input(\"Press Enter to stop recording...\")\n",
        "    audio_data = audio_data.encode()  # Convert to bytes\n",
        "\n",
        "    # Check if the audio data is silent\n",
        "    rms_value = audioop.rms(audio_data, WIDTH)\n",
        "    non_silent = rms_value > 1000\n",
        "\n",
        "    # Write the audio data to the wave file\n",
        "    wf.writeframes(audio_data)\n",
        "    total_audio_data += audio_data\n",
        "\n",
        "# Close the wave file\n",
        "wf.close()\n",
        "\n",
        "# Calculate the time elapsed\n",
        "toc = time.perf_counter()\n",
        "print(f\"{emoji_done} Session ended\")\n",
        "print(f\"🕒 Audio recorded for: {toc - tic:0.4f} seconds\")\n",
        "\n",
        "# Visualize the recorded audio\n",
        "audio_data = np.frombuffer(total_audio_data, dtype=np.int16)\n",
        "print(audio)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(audio_data)\n",
        "plt.title(\"Recorded Audio\")\n",
        "plt.xlabel(\"Time (samples)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n",
        "\n",
        "# Example emotion analysis API URL (replace with your API URL)\n",
        "emotion_api_url = \"https://api.textrics.ai/emotion_analysis_api.php\"\n",
        "\n",
        "\n",
        "# Prepare audio data to send to the emotion analysis API\n",
        "audio_data_to_send = total_audio_data  # You may need to format it according to the API requirements\n",
        "\n",
        "# You can use different emotion analysis APIs here. Example with Text-based API:\n",
        "response = requests.post(emotion_api_url, data=audio_data_to_send)\n",
        "\n",
        "# Visualize the emotion analysis result\n",
        "if response.status_code == 200:\n",
        "    emotion_data = response.json()  # Replace with the actual way the API provides emotion data\n",
        "    print(\"Emotion Analysis Result:\", emotion_data)\n",
        "    # You can visualize or interpret the emotion analysis result here\n",
        "else:\n",
        "    print(\"Error in emotion analysis API request:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "7LogKpklc_5T",
        "outputId": "c5320147-3a64-483c-f371-e4abb3bcfd89"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎤 Recording...\n",
            "Press Enter to stop recording...asdadfsdgdf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-5b463ea34784>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Check if the audio data is silent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mrms_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mnon_silent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrms_value\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: not a whole number of frames"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyAudioAnalysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2BhMY9dasY3",
        "outputId": "af3fffd1-cb40-42a0-c4ae-50f50a1200ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyAudioAnalysis\n",
            "  Downloading pyAudioAnalysis-0.3.14.tar.gz (41.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyAudioAnalysis\n",
            "  Building wheel for pyAudioAnalysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyAudioAnalysis: filename=pyAudioAnalysis-0.3.14-py3-none-any.whl size=41264372 sha256=4230825633b6c01a00188b82cce7ec810c8a9ff2ce041b24b1fca46503078ea3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/54/73/fa830689c2440d2c81ff175c60e374930ad1607a8881e0f43f\n",
            "Successfully built pyAudioAnalysis\n",
            "Installing collected packages: pyAudioAnalysis\n",
            "Successfully installed pyAudioAnalysis-0.3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eyed3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvW7f50ea-eJ",
        "outputId": "7fa0fd7a-23d1-446c-e073-c01aee1a78b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eyed3\n",
            "  Downloading eyed3-0.9.7-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage[toml]<6.0.0,>=5.3.1 (from eyed3)\n",
            "  Downloading coverage-5.5-cp310-cp310-manylinux1_x86_64.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation<3.0.0,>=2.1.0 (from eyed3)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.0.7 (from eyed3)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from coverage[toml]<6.0.0,>=5.3.1->eyed3) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<3.0.0,>=2.1.0->eyed3) (23.2)\n",
            "Installing collected packages: filetype, deprecation, coverage, eyed3\n",
            "Successfully installed coverage-5.5 deprecation-2.1.0 eyed3-0.9.7 filetype-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6JRviWzbFaU",
        "outputId": "598bdbeb-601a-47f6-81c9-b0b9455c0eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2Lp9QLQbTNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}